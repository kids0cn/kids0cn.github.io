<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://kids0cn.github.io</id>
    <title>kids&apos;s Blogger</title>
    <updated>2020-08-22T06:13:07.795Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://kids0cn.github.io"/>
    <link rel="self" href="https://kids0cn.github.io/atom.xml"/>
    <subtitle>精耕细作</subtitle>
    <logo>https://kids0cn.github.io/images/avatar.png</logo>
    <icon>https://kids0cn.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, kids&apos;s Blogger</rights>
    <entry>
        <title type="html"><![CDATA[【8-19】目前主流无人自主飞行上位机套件]]></title>
        <id>https://kids0cn.github.io/post/MqcD5hVjc/</id>
        <link href="https://kids0cn.github.io/post/MqcD5hVjc/">
        </link>
        <updated>2020-08-19T12:33:17.000Z</updated>
        <content type="html"><![CDATA[<p>无人机与无人车不同，需要在三维空间中保持稳态。无人车在没有持续不断的控制信号传入时，会在地面保持静止，即使在控制过程中突然中断信号，无人车也不会出现大的损害。而无人机平台，本身克服地心引力，就需要飞控控制马达一一定的速度旋转。而这种稳态仅仅是在Z轴的稳定。在各种</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【8-14】virtualenv和virtualenv wrapper的使用]]></title>
        <id>https://kids0cn.github.io/post/2eF0kFcC4/</id>
        <link href="https://kids0cn.github.io/post/2eF0kFcC4/">
        </link>
        <updated>2020-08-14T08:00:04.000Z</updated>
        <content type="html"><![CDATA[<p>跟conda类似的Python虚拟环境管理工具，jetson nano暂时无法使用conda</p>
<h2 id="1virtualenv">1.virtualenv</h2>
<pre><code class="language-shell">#安装
sudo pip install virtualenv

#虚拟环境创建      虚拟环境会以文件夹的形式放在~/.virtualenv下面
virtaulenv -p Python版本 虚拟环境名字

#进入环境
source path_to_virutal_enviroment/bin/activate

·source test/bin/activate
·cd test;source bin/activate

#退出环境
deactivate

#删除环境
直接删除环境文件夹
</code></pre>
<h2 id="2virtualenv-wrapper">2.virtualenv wrapper</h2>
<pre><code class="language-shell">#安装
sudo install virtualenvwrapper

#设置自动启动wrapper
把下列命令写入 ~/.bashrc 
source /usr/local/bin/virtualenvwrapper.sh

#创建环境
mkvirtualenv [-a project_path] [-i package] [-r requirements_file] [-p python版本] 名字

#切换工作环境
workon 名字

#退出
deactivate

#删除环境
rmvirtualenv 名字

#列出所有环境
lsvirtualenv 
-b:简短形式
-l:默认的详细信息输出
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【8-14】树莓派3B+ Ubuntu Mate 18.04使用Intel NCS2做人脸识别]]></title>
        <id>https://kids0cn.github.io/post/2qwuZe9Au/</id>
        <link href="https://kids0cn.github.io/post/2qwuZe9Au/">
        </link>
        <updated>2020-08-14T06:35:57.000Z</updated>
        <content type="html"><![CDATA[<p>想要在无人机平台部署CV，但是无人机的机载电脑需要安装ROS，而ROS需要在Ubuntu的平台才能方便使用，所以树莓派3B+上安装的是Ubuntu Mate18.04。<br>
Intel Ncs2（英特尔神经计算棒）官方的文档写的是部署在树莓派官方系统上，而对于其他平台甚至树莓派平台其他版本的系统都不提供支持。<br>
我在安装Intel Nc2到树莓派上时也遇到了很多坑，初始化setupvar.sh的时候，报错</p>
<pre><code class="language-shell">64 bitness python is required
</code></pre>
<p>然后执行demo的时候，自动退出，没法使用。</p>
<p>后来想要在树莓派上直接编译官方的github，也是国外的一篇文章上推荐的。在编译的时候因为被墙，一直疯狂报错，后来连接手机热点，成功编译，但是这时根本找不到如何使用的方法，官方也没有相关文档。最后通过修改setupvar.sh，成功安装。</p>
<h2 id="1intel-ncs2安装">1.Intel Ncs2安装</h2>
<p>下载固件：https://download.01.org/opencv/2020/openvinotoolkit/2020.4/ 并上传到树莓派</p>
<h3 id="11下载解压">1.1下载解压</h3>
<pre><code class="language-shell">cd ~
mkdir intel 
tar -zxvf l_openvino_toolkit_runtime_raspbian_p_2020.4.287.tgz #解压缩
mv  l_openvino_toolkit_runtime_raspbian_p_2020.4.287.tgz openvino  # 重命名

</code></pre>
<h3 id="12修改setupvarsh">1.2修改setupvar.sh</h3>
<pre><code class="language-shell">1.
INSTALLDIR=/home/pi/intel/openvino  # 修改开头的安装目录 为你自己的安装目录

2.
if [ &quot;$python_bitness&quot; != &quot;&quot; ] &amp;&amp; [ &quot;$python_bitness&quot; != &quot;64&quot; ] &amp;&amp; [ &quot;$OS_NAME&quot; != &quot;Raspian&quot; ]; then
    echo &quot;[setupvars.sh] 64 bitness for Python&quot; $python_version &quot;is requred&quot;

修改为
if [ &quot;$python_bitness&quot; != &quot;&quot; ] &amp;&amp; [ &quot;$python_bitness&quot; != &quot;64&quot; ] &amp;&amp; [ &quot;$OS_NAME&quot; != &quot;Ubuntu&quot; ]; then
    echo &quot;[setupvars.sh] 64 bitness for Python&quot; $python_version &quot;is requred&quot;
</code></pre>
<p>修改之后，添加到bashrc</p>
<pre><code class="language-shell">echo &quot;source ~/intel/openvino/bin/setupvars.sh&quot; &gt;&gt; ~/.bashrc
</code></pre>
<p>仅仅出现下面的提示，就成功了<br>
[setupvars.sh] OpenVINO environment initialized</p>
<h3 id="13-更新usb规则">1.3 更新USB规则</h3>
<pre><code class="language-shell">sudo usermod -a -G users &quot;$(whoami)&quot;
sh ~/intel/openvino/install_dependencies/install_NCS_udev_rules.sh
</code></pre>
<h2 id="2运行样例">2.运行样例</h2>
<pre><code class="language-shell"> mkdir build &amp;&amp; cd build
 cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS=&quot;-march=armv7-a&quot; \ 
  ~/intel/openvino/deployment_tools/inference_engine/samples/c
  make -j2 object_detection_sample_ssd_c
# 切换到生成的目录
cd ~/intel/openvino/build/armv7l/Release
# 下载训练好的权重
 wget --no-check-certificate https://download.01.org/opencv/2020/  \   openvinotoolkit/2020.1/open_model_zoo/models_bin/1/face-detection-adas-0001/   \ FP16/face-detection-adas-0001.bin

 wget --no-check-certificate https://download.01.org/opencv/2020/  \   openvinotoolkit/2020.1/open_model_zoo/models_bin/1/face-detection-adas-0001/  \ FP16/face-detection-adas-0001.xml

# 执行测试
./object_detection_sample_ssd_c -m face-detection-adas-0001.xml -d MYRIAD -i /home/pi/face.jpg
</code></pre>
<h2 id="3运行视频的人脸检测">3.运行视频的人脸检测</h2>
<p>效果：https://www.bilibili.com/video/BV17p4y1v7bx/</p>
<pre><code class="language-python">import cv2 as cv
import numpy as np
# 载入模型
net = cv.dnn.readNet('face-detection-adas-0001.xml','face-detection-adas-0001.bin')

# 选择目标设备
net.setPreferableTarget(cv.dnn.DNN_TARGET_MYRIAD)

# 读取图片
print('读取视频')
frame = cv.VideoCapture('/home/pi/face.mp4')
fps = frame.get(cv.CAP_PROP_FPS)
size = (int(frame.get(cv.CAP_PROP_FRAME_WIDTH)), int(frame.get(cv.CAP_PROP_FRAME_HEIGHT)))
output = cv.VideoWriter('/home/pi/face_out.avi',cv.VideoWriter_fourcc(*'XVID'), fps, size)

while(frame.isOpened()):
    ret, fra = frame.read()
    if ret==True:
        blob = cv.dnn.blobFromImage(fra, size=(672,384), ddepth=cv.CV_8U) 
        net.setInput(blob)         
        out = net.forward()
        print('开始处理第一帧')
        # Draw detected faces on the frame 
        for detection in out.reshape(-1, 7): 
            confidence = float(detection[2]) 
            xmin = int(detection[3] * fra.shape[1]) 
            ymin = int(detection[4] * fra.shape[0]) 
            xmax = int(detection[5] * fra.shape[1]) 
            ymax = int(detection[6] * fra.shape[0])
            if confidence &gt; 0.5:
                cv.rectangle(fra, (xmin, ymin), (xmax, ymax), color=(0, 255, 0))
        output.write(fra)
    else:
        break


frame.release()
output.release()
print(&quot;ALL DONE SUCCESSFULLY&quot;)

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【8-13】树莓派安装Dronekit套件，实现对无人机的控制]]></title>
        <id>https://kids0cn.github.io/post/6ZWxURes0/</id>
        <link href="https://kids0cn.github.io/post/6ZWxURes0/">
        </link>
        <updated>2020-08-13T12:04:04.000Z</updated>
        <content type="html"><![CDATA[<p>Dronekit是一套对MAVLink的封装，简化了控制的方法，可以实现通过Python语言对无人机的控制。Dronekit不仅能直接部署在树莓派上实现对无人机的控制，也可以部署在台式机上，通过数传发送无人机的控制指令，这样就可以用台式机进行人工智能的计算，然后结果发送给无人机执行。<br>
本文选择的是部署在树莓派上，通过树莓派直接控制飞控，实现无人机自主飞行。</p>
<h2 id="0树莓派连接无人机">0.树莓派连接无人机</h2>
<p>连接三个口：GND、RT、TX<br>
<img src="https://kids0cn.github.io/post-images/1597321016561.png" alt="" loading="lazy"></p>
<h2 id="1将树莓派3b的无线网卡设置为ap模式">1.将树莓派3B+的无线网卡设置为ap模式</h2>
<p>这样在无人机在室外，可以通过热点登录无人机进行控制。</p>
<pre><code class="language-shell"># 1.clone软件仓库
git clone https://github.com/oblique/create_ap
# 2.安装依赖库
sudo apt-get install util-Linux procps hostapd iproute2 iw haveged dnsmasq
# 3.编译
cd create_ap
make install
# 4.创建热点
sudo create_ap wlan0 eth0 热点名 密码
# 5.开机启动
sudo create_ap wlan0 eth0 热点名 密码 添加到/etc/rc.local当中
</code></pre>
<h2 id="2安装dronekit套件">2.安装Dronekit套件</h2>
<h3 id="21-设置pip源">2.1 设置pip源</h3>
<p>新建 ~/.config/pip.conf后写入</p>
<pre><code class="language-shell">[global]
timeout = 60
index-url = http://pypi.douban.com/simple
trusted-host = pypi.douban.com
</code></pre>
<h3 id="22-安装依赖">2.2 安装依赖</h3>
<pre><code class="language-shell">sudo apt-get install python3-pip python3-dev libxml2 libxslt-dev
pip install pyserial    //python2
pip3 install pyserial   //python3
pip3 install future
</code></pre>
<h3 id="23-安装套件">2.3 安装套件</h3>
<pre><code class="language-shell">pip3 install dronekit
pip3 install dronekit-sitl  # 模拟器，选装，我们自己用的是Gazebo
pip3 install mavproxy # 安装mavlink的转接程序
</code></pre>
<h2 id="3测试">3.测试</h2>
<pre><code class="language-shell">
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【8-12】树莓派部署t265+px4飞控实现无人机视觉定位]]></title>
        <id>https://kids0cn.github.io/post/4sAda0mhj/</id>
        <link href="https://kids0cn.github.io/post/4sAda0mhj/">
        </link>
        <updated>2020-08-13T12:02:31.000Z</updated>
        <content type="html"><![CDATA[<p>在之前的<a href="https://kids0cn.github.io/post/qZKoxBQGg/">文章</a>中，我们已经成功在树莓派（ubuntu mate 18.04）上部署了T265的追踪摄像头。本文将利用MAVROS协议，将T265测量的位姿信息发送给px4固件，实现室内室外无GPS情况下的视觉定位。</p>
<h2 id="0预操作">0.预操作</h2>
<p>前提是树莓派中已经安装了如下组件：</p>
<ul>
<li>T265驱动和相应的ROS驱动</li>
<li>ROS系统</li>
<li>MAVROS包</li>
<li>树莓派已经通过usb或者串口和飞控硬件链接</li>
<li>注意安装位置，可以查看T265的官方文档，了解默认的坐标。安装在飞机上时，镜头正对着地面即可不调整飞机和摄像头的坐标位置。</li>
</ul>
<h2 id="1视觉里程计介绍vio">1.视觉里程计介绍（VIO）</h2>
<p>VIO是一种用来估计移动物体速度和3D位置(局部位置和姿态)的计算机视觉技术。通常用于在GPS信号缺失或者不可靠的情况下的导航(例如在室内或者在桥下飞行)。<br>
VIO采用视觉里程计(Visual Odometry)，通过相机的图像以及结合设备的IMU的惯性测量结果，去估计设备的位置。<br>
本文介绍PX4以及机载电脑如何设置VIO。本文介绍的方法是通过ROS将VIO的信息传输给PX4，PX4本身不在乎接收到的里程信息是从何处传来的。</p>
<h2 id="2安装中介包">2.安装中介包</h2>
<p>T265本身带IMU，可以实时获取机身在三维空间的坐标已经高度和速度信息，将它获取的数据发布给px4的飞行控制器，飞控可以根据这些信息进入position模式（定点）。<br>
中介包有两个，安装自己需要的就行</p>
<ul>
<li>PX4官方写的VIO：https://github.com/Auterion/VIO</li>
<li>APM写的t265_to_mavros：https://github.com/thien94/vision_to_mavros</li>
</ul>
<h2 id="3px4固件调参">3.PX4固件调参</h2>
<p>连接QGC地面站，关于地面站的介绍见这篇<a href="https://kids0cn.github.io/post/HsNe95_fp/">文章</a>。</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Setting for External Position Estimation</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://docs.px4.io/master/zh/advanced_config/parameter_reference.html#EKF2_AID_MASK">EKF2_AID_MASK</a></td>
<td>Set <em>vision position fusion</em>, <em>vision velocity fusion</em>, <em>vision yaw fusion</em> and <em>external vision rotation</em> accoring to your desired fusion model.</td>
</tr>
<tr>
<td><a href="https://docs.px4.io/master/zh/advanced_config/parameter_reference.html#EKF2_HGT_MODE">EKF2_HGT_MODE</a></td>
<td>Set to <em>Vision</em> to use the vision a primary source for altitude estimation.</td>
</tr>
<tr>
<td><a href="https://docs.px4.io/master/zh/advanced_config/parameter_reference.html#EKF2_EV_DELAY">EKF2_EV_DELAY</a></td>
<td>Set to the difference between the timestamp of the measurement and the &quot;actual&quot; capture time. For more information see <a href="https://docs.px4.io/master/zh/computer_vision/visual_inertial_odometry.html#tuning-EKF2_EV_DELAY">below</a>.</td>
</tr>
<tr>
<td><a href="https://docs.px4.io/master/zh/advanced_config/parameter_reference.html#EKF2_EV_POS_X">EKF2_EV_POS_X</a>, <a href="https://docs.px4.io/master/zh/advanced_config/parameter_reference.html#EKF2_EV_POS_Y">EKF2_EV_POS_Y</a>, <a href="https://docs.px4.io/master/zh/advanced_config/parameter_reference.html#EKF2_EV_POS_Z">EKF2_EV_POS_Z</a></td>
<td>Set the position of the vision sensor with respect to the vehicles body frame.</td>
</tr>
</tbody>
</table>
<p>如果被正确配置，通过QGC地面站中的ANYLAZE中的ODOMETRY中查看实时获取的信息。<br>
也可以通过MAVROS发布的ROS节点查看信息</p>
<pre><code class="language-shell">rostopic echo vision_pose/pose
</code></pre>
<p>这个时候移动T265，数值会实时发生变化。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【8-12】树莓派ubuntu升级Cmake]]></title>
        <id>https://kids0cn.github.io/post/8Hwn5sX2W/</id>
        <link href="https://kids0cn.github.io/post/8Hwn5sX2W/">
        </link>
        <updated>2020-08-12T06:03:02.000Z</updated>
        <content type="html"><![CDATA[<p>树莓派上运行的是Ubuntu Mate18.04的系统，自带的cmake版本是3.10.0，编译软件的时候要求cmake版本大于3.11.0。需要进行升级。<br>
<strong>注意</strong>网上的教程会让你卸载现在系统里cmake，就是执行如下的指令：</p>
<pre><code class="language-shell">sudo apt-get autoremove cmake
</code></pre>
<p><strong>千万不要这样操作</strong>，这样操作会顺便把所有cmake编译的程序都卸载掉，比如你的电脑里装好了ros系统，那么就全被干掉了。<br>
<strong>Cmake可以直接用新版本覆盖老版本，不需要卸载旧版本</strong></p>
<p>去Cmake的官网找到需要下载的版本：http://www.cmake.org/files/</p>
<pre><code class="language-shell">getconf LONG_BIT
</code></pre>
<p>检查下系统版本，32就是32位，64为64位<br>
我这里下载的是cmake 3.17.4</p>
<pre><code class="language-shell">wget https://cmake.org/files/v3.17/cmake-3.17.4.tar.gz
tar -zxvf cmake-3.17.4.tar.gz
</code></pre>
<p>进入解压的目录安装</p>
<pre><code class="language-shell">cd cmake-3.17.4
./configure
make
sudo make install
</code></pre>
<p>等待一段时间</p>
<p>检查版本</p>
<pre><code class="language-shell">cmake -version
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【8-11】树莓派上部署英特尔神经网络计算棒Intel NCS2]]></title>
        <id>https://kids0cn.github.io/post/XdBkG1tky/</id>
        <link href="https://kids0cn.github.io/post/XdBkG1tky/">
        </link>
        <updated>2020-08-11T12:05:08.000Z</updated>
        <content type="html"><![CDATA[<p>如果需要在树莓派上进行神经网络和计算机视觉的操作，仅仅依靠树莓派的性能，是远远不够的。而英特尔神经计算棒就可以用来进行CV的计算，从而在树莓派上部署人脸识别，手势识别之类的CV算法。<br>
<strong>注意：</strong></p>
<ul>
<li>树莓派必须使用树莓派官方系统Raspian。</li>
<li>树莓派上部署的工具包，仅能用来进行计算推理，其余功能需要用笔记本或者台式计算机。</li>
<li>官网的安装目录为 /opt/intel/openvino，也有博客建议安装到自己的本地目录，这里安装在~/intel/openvino</li>
</ul>
<h1 id="1驱动安装">1.驱动安装</h1>
<h2 id="1下载安装包">1.下载安装包</h2>
<pre><code class="language-shell">sudo mkdir -p ~/intel/openvino #建立一个文件夹
wget https://download.01.org/opencv/2020/openvinotoolkit/2020.4/\
  l_openvino_toolkit_runtime_raspbian_p_2020.4.287.tgz 
sudo tar -zxvf l_openvino_toolkit_runtime_raspbian_p_2020.4.287.tgz --strip 1 \ -C ~/intel/openvino
</code></pre>
<h2 id="2安装需要的工具">2.安装需要的工具</h2>
<pre><code class="language-shell">sudo apt install cmake
sudo apt-get install libgflags-dev
</code></pre>
<h2 id="3设置环境变量">3.设置环境变量</h2>
<p>直接将环境变量写入.bashrc文件</p>
<pre><code class="language-shell">echo &quot;source ~/intel/openvino/bin/setupvars.sh&quot; &gt;&gt; ~/.bashrc
source ~/.bashrc 
</code></pre>
<p>显示已经初始化完成<br>
[setupvars.sh] OpenVINO environment initialized</p>
<h2 id="4添加usb规则">4.添加USB规则</h2>
<p>不添加规则，树莓派无法访问设备</p>
<pre><code class="language-shell">sudo usermod -a -G users &quot;$(whoami)&quot;
</code></pre>
<p>退出重新登录</p>
<pre><code class="language-shell">sh ~/intel/openvino/install_dependencies/install_NCS_udev_rules.sh
</code></pre>
<h1 id="2运行测试">2.运行测试</h1>
<h2 id="1创建文件夹编译样例">1.创建文件夹编译样例</h2>
<pre><code class="language-shell">cd ~/intel/openvino/deployment_tools/inference_engine/samples/c
mkdir build
cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS=&quot;-march=armv7-a&quot;
 make -j4 object_detection_sample_ssd
</code></pre>
<h2 id="2下载权重文件">2.下载权重文件</h2>
<p>这里是官方自己的训练权重，以后用自己的模型，也需要提前训练好权重文件，并且转换为计算棒支持的格式<br>
现在的文件夹为：<br>
~/intel/openvino/deployment_tools/inference_engine/samples/c</p>
<pre><code class="language-shell">wget --no-check-certificate https://download.01.org/openvinotoolkit/2018_R4/open_model_zoo/face-detection-adas-0001/FP16/face-detection-adas-0001.bin

wget --no-check-certificate https://download.01.org/openvinotoolkit/2018_R4/open_model_zoo/face-detection-adas-0001/FP16/face-detection-adas-0001.xml
</code></pre>
<h2 id="3运行示例">3.运行示例</h2>
<pre><code class="language-shell">./armv7l/Release/object_detection_sample_ssd_c -m face-detection-adas-0001.xml -d MYRIAD -i  图片路径
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【2020-8-9】APM,PX4,GAZEBO,MAVLINK,MAVROS,ROS之间的关系以及科研设备选型]]></title>
        <id>https://kids0cn.github.io/post/HsNe95_fp/</id>
        <link href="https://kids0cn.github.io/post/HsNe95_fp/">
        </link>
        <updated>2020-08-09T14:21:38.000Z</updated>
        <content type="html"><![CDATA[<h2 id="0概述">0.概述</h2>
<p>无人机自主飞行平台可以分为四个部分：动力平台，飞行控制器，机载电脑和模拟平台。</p>
<ul>
<li><strong>动力平台</strong>：负责执行飞行任务，包括螺旋桨、电机、机架等，用于科研的一般都是F380和F450的机架。</li>
<li><strong>飞行控制器</strong>：无人机使用的控制器取决于采用的固件：apm和pixhawk。用来调整无人机在空间中的位姿，给各个螺旋桨发送指令。</li>
<li><strong>机载电脑</strong>：作为上位机，通过MAVROS或者mavlink协议跟飞控通讯。可以搭载更多的机载设备诸如相机，各类传感器，通过机载电脑感知周围环境，做出更多智能化的工作。常见的机载电脑有x86平台的upboard，树莓派，英伟达的jetson。我们自己的实验平台机载电脑使用的是树莓派3b+，飞控是pixhawk，搭在了intel的realsense摄像头，深度摄像头，超声波和激光传感器。</li>
<li><strong>模拟平台</strong>：无人机作为航空设备，操作复杂，危险性高，就算是成熟的商业产品诸如大疆，也存在很多的炸鸡事故。所以，在进行实际飞行之前，一定要进行模拟操作，将程序修改好之后，才可以进行实机测试。</li>
</ul>
<h2 id="1apm和px4飞行控制器和">1.APM和PX4：飞行控制器和</h2>
<p>APM和PX4是自动驾驶和无人机领域最出名的两个固件。而因为历史原因，国内在两个固件的叫法上一直巨大的混淆。<br>
淘宝上比较常见的无人机飞控固件大体分为三类：APM，pixhawk2.4.8和pixhawk4。其中apm价格最便宜，px4价格最便宜。一般的无人机玩家，从预算考虑会购买apm，稍微预算充足的会购买pixhawk2.4.8的硬件。虽然从硬件配置和性能上，apm的硬件是远远不如pixhawk2.4.8的。<br>
但是一般用户购买的pixhawk产品，商家会提供一些pix_3.*.*之类的固件，这些固件实际上是乐迪公司修改过的apm的固件，商家提供的地面站也是apm公司mp地面站，而且是版本较老，汉化不全地面站。<br>
如果仅仅把无人机当做航拍设备，或者就是自己遥控玩一玩，这种刷着乐迪修改版固件的飞机是足够稳定的，还可以搭配乐迪自己的光流传感器和超声波避障模块，足够稳定，不管是室内还是室外。<br>
但是，如果需要用机载电脑进行自主控制，这一套就玩不转。<br>
如果需要使用px4的固件，则需要访问下面的地址，下载QGC地面站，刷pixhawk官方的固件。px4的固件最新的版本号也只有1.10.0。</p>
<p>APM网站：https://ardupilot.org/dev/index.html<br>
PX4网站：https://docs.px4.io/master/en/index.html</p>
<h2 id="2地面站missionplanmp和qgroundcontrolqgc">2.地面站：MissionPlan(MP)和QGroundControl(QGC)</h2>
<h3 id="21-apm">2.1 APM</h3>
<p>MP是APM公司推出的地面站软件，用来进行apm飞控的固件刷写，更新和监控飞行器状态，定点飞行的规划。国内常见的是不知道哪个大佬汉化的版本，汉化不全，版本很老，刷的固件也是乐迪公司修改过的固件。最新版的MP地面站和固件，可以通过访问上面的网站获取。</p>
<h3 id="22-px4">2.2 PX4</h3>
<p>QGroundControl（QGC）是px4官方出的地面站，用来进行px4固件的刷写，调参，监控飞行状态，定点飞行规划。一般国内玩家使用的较少，然而刷了PX4固件的机器，是没法跟APM地面站进行数据通信的，所以如果需要使用PX4的平台，就必须使用QGC，国内也有汉化版可以下载。</p>
<h2 id="2mavlink和mavros通信协议">2.MAVLINK和MAVROS：通信协议</h2>
<p>MAV协议是上位机和飞控通信的通信协议，MAVROS是基于ROS系统的MAV协议，可以和ROS系统相结合。</p>
<h2 id="3gazebo仿真软件">3.GAZEBO仿真软件</h2>
<p>Gazebo是ROS系统自带的仿真平台，可以通过mavros通信协议，将飞控的操作数据反馈到仿真平台。进行无人机的仿真操作。</p>
<h2 id="4ros机器人操作系统">4.ROS：机器人操作系统</h2>
<p>国际最通用的机器人操作系统，将不同硬件的操作进行封装，通过简单的话题发布和订阅，可以让算法开发者不必考虑不同的硬件平台，以及各种硬件之间的配合，仅需要用自己的熟悉的Python或者C++语言编写算法，ROS负责联通算法实施和硬件驱动和模拟仿真。</p>
<h2 id="5自主无人飞行平台选型">5.自主无人飞行平台选型</h2>
<p>PX4官方出了整套解决方案px4-vision价格大概在16000元，国内有阿木实验室在做整机销售，树莓派版本也在12000多左右。我们自己做的性能相近或者超越的整机平台价格在6000以下。有需要的也可以联系我们。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【2020-8-8】树莓派+Ubuntu18.04编译Dji Guidance ROS]]></title>
        <id>https://kids0cn.github.io/post/TGQMWjI7t/</id>
        <link href="https://kids0cn.github.io/post/TGQMWjI7t/">
        </link>
        <updated>2020-08-08T11:16:06.000Z</updated>
        <content type="html"><![CDATA[<p>实验室还有一批大疆的M100和配套的Guidance，但是一直没有玩起来，大疆官方也早就抛弃了这个平台，不再提供技术支持。<br>
今天在树莓派上编译Intel Realsense的固件的时候，看到大疆之前还提供了适用于16.04的guidance_ros的包，就试着编译了一下。结果正常，只需要修改一些地方。明天用到机器上试试。<br>
由于dji在16年发布，17年基本上就被大疆抛弃了，所以只能识别出openc2。所以修改掉源文件的CMakelist。</p>
<pre><code class="language-c">cmake_minimum_required(VERSION 2.8.3)
project(guidance)

find_package(catkin REQUIRED COMPONENTS
  roscpp
  cv_bridge
  std_msgs
  sensor_msgs
  geometry_msgs
)
#####
find_package(OpenCV 2 REQUIRED core highgui)
#####
catkin_package(
)

include_directories(
  ${OpenCV_INCLUDE_DIRS}
  ${catkin_INCLUDE_DIRS}
  include
)

message(&quot;System is: &quot; ${CMAKE_SYSTEM_PROCESSOR})
if (${CMAKE_SYSTEM_NAME} MATCHES &quot;Linux&quot;)
  if (CMAKE_SIZEOF_VOID_P EQUAL 4)
    message(&quot;-- 32bit detected&quot;)
    link_directories(lib/x86)
  elseif (CMAKE_SIZEOF_VOID_P EQUAL 8)
    message(&quot;-- 64bit detected&quot;)
    link_directories(lib/x64)
  endif ()
else()
  message(&quot;-- Non-linux platform detected but sorry we do not support :D&quot;)
endif ()

if (${CMAKE_SYSTEM_PROCESSOR} MATCHES &quot;armv7l&quot; )
  message(&quot;-- &quot; ${CMAKE_SYSTEM_PROCESSOR} &quot; detected&quot;)
  link_directories(lib/XU3)
else ()
endif ()

##cyril add the following
message(STATUS &quot;OpenCV library status:&quot;)
message(STATUS &quot;    version: ${OpenCV_VERSION}&quot;)
message(STATUS &quot;    libraries: ${OpenCV_LIBS}&quot;)
message(STATUS &quot;    include path: ${OpenCV_INCLUDE_DIRS}&quot;)

link_libraries(
  ${OpenCV_LIBS}
  ${catkin_LIBRARIES}
  DJI_guidance

  usb-1.0
  yaml-cpp)

add_executable(guidanceNode
  src/GuidanceNode.cpp
  src/DJI_utility.cpp)

add_executable(guidanceNodeTest
  src/GuidanceNodeTest.cpp)

add_executable(guidanceNodeCalibration
  src/GuidanceNodeCalibration.cpp
  src/DJI_utility.cpp)
</code></pre>
<p>修改标注出来的地方，去掉2就行。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【20-8-7】树莓派上部署英特尔深度相机IntelRealsense T265]]></title>
        <id>https://kids0cn.github.io/post/qZKoxBQGg/</id>
        <link href="https://kids0cn.github.io/post/qZKoxBQGg/">
        </link>
        <updated>2020-08-07T11:55:39.000Z</updated>
        <content type="html"><![CDATA[<p>最近在搭建无人机的自主飞行平台，无GPS的情况下室内定位的方案除了光流，最好的就是配合intel的realsense系列的摄像头。尤其是T265本身带IMU，可以直接给飞控输出位姿信息，不管是APM固件还是PX4固件，在ROS和MAVROS的帮助下，都可以直接获取T265的信息。<br>
自主飞行平台的板载电脑是树莓派3b+，运行ubuntu mate 18.04的系统和ROS Melodic，理论上可以随时更换为性能更强劲的英伟达Jetson系列系统，或者intel upboard系列。<br>
ROS的安装，在其他的文章中已经讲过了。本文只涉及部署Intel的T265相机。分为两个部分，SDK的安装和ROS节点的安装。前提是ROS系统已经被部署在树莓派上。</p>
<h2 id="0-预操作扩大swap分区">0. 预操作：扩大Swap分区</h2>
<p>Ubuntu mate默认的Swap分区太小，编译时会直接卡死，并且不会报错，所以首先要扩大swap分区。另外，编译操作会让树莓派温度升高的很厉害，需要安装好散热风扇。<br>
查看当前的交换空间大小，我的默认是100M</p>
<pre><code class="language-shell">free -m 
</code></pre>
<p><strong>1.建立交换空间文件</strong><br>
随便在哪里都行，放到碰不到的地方，防治误删除</p>
<pre><code class="language-shell">cd /opt/
sudo mkdir swap_temp #名字任意起
cd swap_temp
sudo touch swap

</code></pre>
<p><strong>2.设置交换文件的大小</strong></p>
<pre><code class="language-shell">sudo dd if=/dev/zero of=/opt/swap_temp/swap bs=1024 count=3048000  # 我这里设置的是3G
</code></pre>
<p>等一会儿，结束时才会有回显，我的写入速度是20M每秒，3G需要2分钟左右<br>
结束后返回：</p>
<pre><code>3048000+0 records in
3048000+0 records out
2097152000 bytes (2.9 GB, 3.0 GiB) copied, 242.095 s, 18.7 MB/s
</code></pre>
<p><strong>3.设置为交换空间</strong></p>
<pre><code class="language-shell">sudo mkswap /opt/swap_temp/swap
</code></pre>
<p><strong>4.启用交换空间</strong></p>
<pre><code class="language-shell">sudo swapon /opt/swap_temp/sawp
</code></pre>
<p>现在已经可以使用了，通过free -m查看</p>
<p><strong>5.写入分区</strong></p>
<pre><code class="language-shell">sudo vim /etc/fstab
文件最后加入
/opt/swap_temp/sawp /swap swap defaults 0 0
</code></pre>
<h2 id="1intel-realsense-sdk的安装">1.Intel Realsense SDK的安装</h2>
<p><strong>1.安装依赖包</strong></p>
<pre><code class="language-shell">sudo apt-get update &amp;&amp; sudo apt-get upgrade &amp;&amp; sudo apt-get dist-upgrade
sudo apt-get install git cmake libssl-dev libusb-1.0-0-dev pkg-config libgtk-3-dev
sudo apt-get install libglfw3-dev libgl1-mesa-dev libglu1-mesa-dev
</code></pre>
<p>第二行的是核心依赖，必装。第三行是3D相关的依赖，如果不打算使用realsense-viewer，可以不装，树莓派性能有限，安装SDK的目的是为了安装好驱动，不需要执行太多本机操作，建议内存卡小的不用装了。</p>
<p><strong>3.下载Realsense SDK</strong></p>
<pre><code class="language-shell">git clone https://github.com/IntelRealSense/librealsense.git
</code></pre>
<p><strong>4.编译准备</strong></p>
<pre><code class="language-shell">cd librealsense
mkdir build &amp;&amp; cd build
cmake ../ -DCMAKE_BUILD_TYPE=Release -DBUILD_EXAMPLES=true \
-DFORCE_RSUSB_BACKEND=ON -DBUILD_WITH_TM2=false -DIMPORT_DEPTH_CAM_FW=false
</code></pre>
<p><strong>-DFORCE_RSUSB_BACKEND=ON 必选，强制LIBUVC后端，否则你要自己给内核打补丁。</strong><br>
<strong>5.编译</strong></p>
<pre><code class="language-shell">sudo make uninstall &amp;&amp; make clean &amp;&amp; make -j2 &amp;&amp; sudo make install -2
</code></pre>
<p><img src="https://kids0cn.github.io/post-images/1596802908724.png" alt="" loading="lazy"><br>
我自己的3B+需要编译三小时左右。中间交换空间最大占用为1.6G。</p>
<p><strong>6.设置udev规则</strong></p>
<pre><code class="language-shell">sudo ./scripts/setup_udev_rules.sh
</code></pre>
<p>主要是为了识别设备，最重要的也就是这里<br>
<strong>7.测试</strong></p>
<pre><code class="language-text">realsense-viewer
</code></pre>
<p>我的机载电脑没有开图形界面，一般都是VNC连接上去。</p>
<h2 id="2-编译ros驱动">2. 编译ROS驱动</h2>
<p>目的是为了让ROS节点可以订阅T265发回的IMU信息。<br>
英特尔官方发布了两种安装方式，1是通过apt的方式安装二进制文件，2是通过源码编译。但是前提是系统里已经安装好了对应的ROS系统，我的是18.04+Melodic</p>
<h3 id="21-apt-get-安装">2.1 APT-Get 安装</h3>
<pre><code class="language-shell">export ROS_VER=melodic
</code></pre>
<p>安装</p>
<pre><code class="language-shell">sudo apt-get install ros-$ROS_VER-realsense2-camera
</code></pre>
<p>用于3D显示的库</p>
<pre><code>sudo apt-get install ros-$ROS_VER-realsense2-description
</code></pre>
<p>注意：</p>
<ul>
<li>这种方法安装的librealsense2总是落后于最新发布的版本</li>
</ul>
<h3 id="22-源码编译">2.2 源码编译</h3>
<h5 id="1创建工作目录">1.创建工作目录</h5>
<p>工作目录的名字不一定要是catkin_ws</p>
<pre><code class="language-shell">mkdir -p ~/catkin_ws/src
cd ~/catkin_ws/src/
</code></pre>
<h5 id="2克隆源码">2.克隆源码</h5>
<pre><code class="language-shell">git clone https://github.com/IntelRealSense/realsense-ros.git
cd realsense-ros/
git checkout `git tag | sort -V | grep -P &quot;^\d+\.\d+\.\d+&quot; | tail -1`
cd ..
</code></pre>
<h5 id="3编译">3.编译</h5>
<pre><code class="language-shell">catkin_init_workspace
cd ..
catkin_make clean
catkin_make -DCATKIN_ENABLE_TESTING=False -DCMAKE_BUILD_TYPE=Release
catkin_make install
echo &quot;source ~/catkin_ws/devel/setup.bash&quot; &gt;&gt; ~/.bashrc
source ~/.bashrc
</code></pre>
<h3 id="3使用">3.使用</h3>
<p>启动节点</p>
<pre><code class="language-shell">roslaunch realsense2_camera rs_camera.launch
</code></pre>
]]></content>
    </entry>
</feed>